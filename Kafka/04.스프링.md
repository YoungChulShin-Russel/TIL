# 스프링
스프링에서 카프카를 사용하기 위한 방법
1. 카프카 클라이언트를 이용해서 Java 기반으로 코드 작성
2. spring-kafka를 이용해서 조금 더 추상화된 개념으로 코드 작성
3. spring-cloud를 이용해서 더 추상화된 개념으로 작성
   - spring-cloud를 이용하면 binder 정보를 변경해서 kafka, kinesis 등을 변경할 수 있다

기본 카프카 라이브러리를 사용할 때와 차이점
- `KafkaTemplate`과 `KafkaListener`룰 이용해서 조금 더 부가적인 기능을 사용할 수 있다
   - 예: 레코드 단위 처리, 배치 처리 등을 구분할 수 있고, 필요에 따라서 비동기 커밋도 가능하다. 
- application.yml을 이용해서 설정을 할 수 있다
- concurency 설정을 통해서 쉽게 스레드를 확장해서 처리할 수 있다
- KafkaListener를 사용하기 때문에 코드 더 간편해진다

# 프로듀서
KafkaTemplate을 이용해서 메시지를 전달할 수 있다. 
```java
private final KafkaTemplate<String, String> kafkaTemplate;
kafkaTemplate.send(topicName, "test-" + i);
```

기본 템플릿은 바로 의존성을 주입받아서 사용할 수 있고, 개별 설정이 필요하다면 빈을 정의하면 된다. 

커스텀 템플릿은 Java 기반에서 코드를 작성하는 것과 거의 동일하다. 
```java
@Bean
public KafkaTemplate<String, String> customKafkaTemplate() {
   Map<String, Object> props = new HashMap<>();
   props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
   props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
   props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

   DefaultKafkaProducerFactory<String, String> pf = new DefaultKafkaProducerFactory<>(props);

   return new KafkaTemplate<>(pf);
}
```

전달 콜백
- KafkaTemplate.send()의 응답은 ListenableFuture이다. 
- callback을 추가해서 전달의 성공/실패 여부를 확인할 수 있다
   ```java
   ListenableFuture<SendResult<String, String>> ack = template.send(TOPIC_NAME, "test" + i);
   ack.addCallback(new ListenableFutureCallback<SendResult<String, String>>() {
      @Override
      public void onFailure(Throwable ex) {
         System.out.println("Send-Fail: " + ex.getMessage());
      }

      @Override
      public void onSuccess(SendResult<String, String> result) {
         System.out.println("Send-Success: " + result.getProducerRecord().value());
      }
   });
   ```

# 컨슈머 
메시지 처리
- RECORD: Record 단위로 데이터를 가져와서 치라한다
   - 예: `T`, `ConsumerRecord<K, V>` 형식으로 가져와서 사용할 수 있다 
- BATCH: Batch 단위로 데이터를 가져와서 처리한다
   - 예: `List<T>`, `ConsumerRecords<K, V>` 형식으로 가져와서 사용할 수 있다
- 스프링 옵션
   ```yaml
   spring:
      kafka:
         consumer:
            bootstrap-servers: localhost:19092,localhost:29092,localhost:39092
         listener:
            type: single  # 레코드 타입의 리스너 구현
   ```
수동 커밋
- 조건: 수동 커밋이기 때문에 ack_mode를 `manual` 또는 `manual_immediate` 로 해야한다
- 아래 파라미터를 이용해서 수동 커밋을 할 수 있다
   - Consumer 파라미터: Consumer를 파라미터로 주입받아서 처리할 수 있다. 
      - Consumer가 가지고 있는 커밋, 비동기 커밋을 사용할 수 있고, 콜백을 사용할 수도 있다
   - Acknowledgment 파라미터: `acknowledgment.acknowledge()`를 이용해서 커밋시점을 정할 수 있다

커밋
- Java 구현에서는 오토 커밋, 동기 커밋, 비동기 커밋 3가지였지만 스프링 카프카는 더 많은 항목을 지원한다
- 종류
   - RECORD: 레코드 단위로 프로세싱 이후 커밋
   - BATCH(기본): poll() 호출된 레코드가 모두 처리된 이후에 커밋
   - TIME: 특정 시간 이후에 커밋
   - COUNT: 특정 갯수 이후에 커밋
   - COUNT_TIME: TIME, COUNT 옵션 중 하나라도 만족하면 커밋
   - MANUAL: Acknowledgement.acknowledge() 메서드가 호출되면 다음 poll() 때 커밋
      - Acknowledgement를 전달 받는 리스너를 구현해야한다
   - MANUAL_IMMEDIATE: Acknowledgement.acknowledge() 메서드가 호출되면 즉시 커밋
      - Acknowledgement를 전달 받는 리스너를 구현해야한다

Application 설정은 공식 홈페이지를 참고한다
- https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html
- 설정 예시
   ```yaml
   spring:
      kafka:
         consumer:
            bootstrap-servers: localhost:19092,localhost:29092,localhost:39092
         listener:
            type: single  # 레코드 타입의 리스너 구현
   ```

`@KafkaListener`를 이용해서 메지를 가져올 수 있다
- 기본 예제
   ```java
   @KafkaListener(
      topics = "test",
      groupId = "test-group-00")
   public void recordListener(ConsumerRecord<String, String> record) {
      logger.info("[test-group-00] {}", record.value());
   }
   ```
- 동시성 처리 예제: concurrency 값으로 내부적으로 스레드를 만들어서 처리한다
   ```java
   @KafkaListener(
      topics = "test",
      groupId = "test-group-03",
      concurrency = "3")
   ```
- Consumer 예제
   ```java
   @KafkaListener(
         topics = "test",
         groupId = "test-group-3")
   public void consumerCommitListener(List<String> records, Consumer<String, String> consumer) {
      logger.info("[test-group-1] start");
      records.forEach(record -> logger.info("[test-group-1] {}", record));
      logger.info("[test-group-1] end");

      consumer.commitAsync((offsets, exception) -> logger.info("[test-group-1] complete"));
   }
   ```

KafkaListener
- topic 등의 값을 클래스 내 상수가 아니라, Property 또는 Bean으로도 설정해서 가져올 수 있다
   - https://docs.spring.io/spring-kafka/reference/html/#kafka-listener-annotation