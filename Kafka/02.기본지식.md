# 기본 개념
카프카 브로커
- 카프카 클라이언트와 데이터를 주고 받기 위해 사용하는 주체
- 하나의 서버에 한개의 브로커 프로세스가 실행
- 1대로도 동작하지만 보통 고가용성을 위해서 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 사용한다
- 데이터는 파일 시스템에 저장한다. 메모리, DB, 캐시 메모리를 사용하지 않는다. 
   - 속도 문제는 페이지캐시(OS에서 파일 입출력의 성능 향상을 위해 만들어 놓은 메모리 영역)를 사용하여 문제를 해결

카프카 클러스터
- n개의 카프카 브로커의 그룹
- 저장 데이터
   - 브로커 정보
   - 컨트롤러 정보
   - 토픽 정보
- tree 구조의 znode(데이터 저장 단위)로 관리된다

주키퍼
- 카프카의 메타데이터를 관리한다

데이터 복제
- 파티션 단위로 일어난다
- 복제 개수가 2개 이상이면 리더, 팔로워 파티션으로 나뉜다
   - 리더는 프로듀서, 컨슈머와 직접 통신하는 파티션
   - 팔로워는 리더 파티션의 오프셋을 확인하고 리더파티션으로 부터 데이터를 가져와서 자신의 파티션에 저장한다

컨트롤러
- 클러스터의 다수 브로커중 한대가 컨트롤러의 역할을 한다
- 컨트롤러는 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지면 리더파티션을 재분배한다

데이터 삭제
- 컨슈머가 데이터를 가져가더라도 삭제되지 않으며, 컨슈머나 프로듀서가 데이터를 삭제요청 할 수도 없다
- '로그 세그먼트'라는 파일 단위로 삭제가 이루어진다.

컨슈머 오프셋 저장
- 특정 파티션으로부터 데이터를 가져가고 오프셋을 커밋한다
- 커밋한 오프셋은 `'_consumer_offsets'` 토픽에 저장한다

코디네이터
- 클러스터의 다수 브로커 중 한 대는 코디네이터 역할을 수행한다
- 코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다
   - 컨슈머가 컨슈머그룹에서 빠지면 매칭되지 않는 파티션을 정상 동작하는 컨슈머로 할당하여 데이터가 처리되도록 한다
   - 이 과정을 리밸런싱이라고 한다

# 프로듀서
데이터 전송 개념
1. KafkaProducer가 데이터를 전송
2. ProduceRecord를 생성한다
   - 토픽, 파티션, 키, 밸류, 타임스탬프가 포함된다
3. KafkaProducer.send() 호출
4. Partitioner를 통해서 어느 토픽, 어느 파티션에 들어갈 지 정해진다
   - Partitoner는 기본적으로 아래 2개가 있고, 2.4.0 버전부터는 UniformStickyPartitioner가 기본 값으로 사용된다
   - UniformStickyPartitioner가: 배치로 데이터를 받아서 배치 데이터가 모두 같은 파티션에 저장한다. 성능 향상
   - RoundRobinPartitioner: 배치로 데이터를 받아서 각각의 파티션을 라운드로빈 하면서 저장한다
5. 일정 데이터가 모이면 클러스터로 전송된다

압축을 지원한다
- 다만 압축은 압축을 하는 리소스와 컨슈머에서 받았을 때 압축을 푸는 리소스를 고려해야한다

옵션
- bootstrap.servers(필수): 브로커 IP, Port 정보
- key.serializer(필수): 메시지 키를 직렬화하는 클래스
- value.serializer(필수): 메시지 값을 직렬화하는 클래스
- acks: 전송한 데이터를 브로커가 잘 받았는지 확인하는 옵션
   - 0: 전송 즉시 브로커에 저장 여부 상관없이 성공 판단
   - 1: 리더가 응답을 주면 성공으로 판단
   - -1: 모든 브로커가 응답을 주면 성공으로 판단
- buffer.memory: 브로커로 전송할 데이터를 배치로 모으기 위해 설정한 버퍼 메모리 양
- batch.size: 배치로 전송할 레코드 최대 용량. 기본 값은 16384
- linger.ms: 배치를 전송하기 전까지 기다리는 시간
- partitioner.class: 파티셔너 클래스 지정

메시지 키
- 키의 해시 값을 이용해서 파티션을 매칭한다. 그래서 동일한 메시지키는 