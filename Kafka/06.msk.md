# MSK (Managed Streaming for Kafka)
### MSK 특징
다른 On-Premise 서비스와 같겠지만, 가격적인 측면에서 붊리함이 있다. 하지만 직접 운영할 경우에 발생하는 유지보수/인력 비용을 생각할 때 결코 비싸다고만은 할 수 없다

### BootstrapServer, Zookeeper 정보 확인
접속 정보 확인
- Cluster에서 `View clinet information` 버튼을 통해서 정보를 확인할 수 있다
- zookeeper는 plaintext를 이용해서 접속할 수 있는데, broker는 tls를 이용해서 접속해야한다.

Java truststore를 이용해서 Brocker에 접속 방법
1. jdk 설치 경로에서 'jre/lib/security/cacerts' 파일을 사용할 경로로 복사한다
2. consumer, producer에서 사용할 properties 파일을 만든다
   ```
   // client.properties
   security.protocol=SSL
   ssl.truststore.location=<<file location>>
   ```
3. consumer/producer 실행 시, `consumer.config`/`producer.config` 옵션에 파일을 지정해준다


### Exporter를 이용한 지표수집
MSK의 Monitoring을 보면 cloudwatch를 이용해서 기본적인 지표를 수집할 수 있고, 추가적인 비용을 지불하면 브로커, 토픽에 대한 정보를 수집할 수 있다.

이 대신 Exporter를 이용하면 프로메터우스로 지표를 가져와서 데이터를 보여줄 수 있다

Exporter
- 개념: 모니터링 지표를 가져오기 위한 인터페이스 역할을 하는 프록스 애플리케이션. 
- 프로메테우스는 Pull 방식으로 모니터링 대상의 지표를 가져온다. 모니터링 대상은 특정 포트로 네트워크가 열려있어야한다. 
- MSK에는 2개의 exporter가 있다
   - JMX exporter
      - 브로커의 카프카 관련 지표를 가져갈 수 있다
      - 지표 정보: https://kafka.apache.org/documentation/#monitoring
   - node exporter
      - EC2의 컴퓨팅 지표를 수집할 수 있다
      - github: https://github.com/prometheus/node_exporter
      - 설정 정보: https://prometheus.io/docs/guides/node-exporter/#node-exporter-metrics
      - 지표 리스트: /metrics 로 확인 가능

### Prometheus 연동
cluster를 생성할 때, exporter를 사용하는 것으로 해주면, 특정 포트로 프로메테우스가 메트릭 정보를 가져갈 수 있다. 

exporter 연동을 위한 설정
1. json 파일에 대상 exporter 정보 설정
   - msk 클러스터에서 실행중인 exporter는 각각 아래 포트를 사용한다
      - JMX: 11001
      - node: 11002
   - 브로커의 호스트에 포트를 입력해서 접속할 수 있다
   - 설정 정보
      ```json
      [
        {
                "labels": {
                        "job": "jmx"
                },
                "targets": [
                        "b-1.ycshinmsk.7arwuf.c4.kafka.ap-northeast-2.amazonaws.com:11001",
                        "b-2.ycshinmsk.7arwuf.c4.kafka.ap-northeast-2.amazonaws.com:11001",
                        "b-3.ycshinmsk.7arwuf.c4.kafka.ap-northeast-2.amazonaws.com:11001"
                ]
        },
        {
                "labels": {
                        "job": "node"
                },
                "targets":[
                        "b-1.ycshinmsk.7arwuf.c4.kafka.ap-northeast-2.amazonaws.com:11002",
                        "b-2.ycshinmsk.7arwuf.c4.kafka.ap-northeast-2.amazonaws.com:11002",
                        "b-3.ycshinmsk.7arwuf.c4.kafka.ap-northeast-2.amazonaws.com:11002"
                ]
        }
      ]
      ```
2. prometheus.yml 파일에 신규 파일 추가
   ```yml
   scrape_configs:
      # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
      - job_name: "prometheus"
         # metrics_path defaults to '/metrics'
         # scheme defaults to 'http'.
         static_configs:
            - targets: ["localhost:9090"]
      - job_name: 'broker'
         file_sd_configs:
         - files:
            - 'targets.json'
   ```
3. 설정 이후에 프로메테우스 실행
   ```
   nohup sh -c './prometheus' -> prometheus.log &
   ```
4. 접속 확인
   - 9090 포트를 이용해서 접속할 수 있다
   - 접속하면 'Status -> Target' 메뉴를 이용해서 연결상태를 확인할 수 있다. Status가 초록색 'up'으로 나와야한다. 